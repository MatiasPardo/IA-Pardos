
# IA Pardo Final Setup ğŸš€

Este proyecto contiene:
âœ… **Backend** (Node.js) â†’ API que comunica con Ollama
âœ… **Ollama** (IA) â†’ 3 modelos de lenguaje disponibles
âœ… **Frontend** (HTML estÃ¡tico) â†’ Servido por NGINX
âœ… **Portainer** â†’ AdministraciÃ³n web de Docker
âœ… **ConfiguraciÃ³n completa** en un solo `docker-compose.yml`

---

## ğŸ¢ **Arquitectura del Sistema**

```
ğŸŒ Internet
    â”‚
    â†“ Puerto 80
ğŸ“¦ NGINX (Frontend)
    â”‚
    â”œâ”€â”€ Sirve: index.html, chat/index.html
    â””â”€â”€ Proxy: /api/ â†’ Backend
    â”‚
    â†“ Red interna: pardos-network
ğŸ“¦ Backend (Node.js) - Puerto 3000
    â”‚
    â””â”€â”€ Conecta: http://ollama:11434
    â”‚
    â†“ Red interna: pardos-network
ğŸ¤– Ollama (IA)
    â”‚
    â”œâ”€â”€ llama3:8b (modelo base)
    â”œâ”€â”€ pardos-assistant:latest (personalizado)
    â””â”€â”€ llama3-base (base optimizado)

ğŸ“Š Portainer (Puerto 9000)
    â””â”€â”€ Administra todos los contenedores
```

### ğŸ“‹ **Componentes:**

| Servicio | Contenedor | Puerto | FunciÃ³n |
|----------|------------|--------|----------|
| **Frontend** | `pardos-frontend` | 80 | Interfaz web + Proxy NGINX |
| **Backend** | `pardos-backend` | 3000 | API REST para chat |
| **Ollama** | `pardos-ollama` | 11434 (interno) | Modelos de IA |
| **Portainer** | `pardos-portainer` | 9000 | AdministraciÃ³n Docker |

### ğŸŒ **Red y VolÃºmenes:**

- **Red:** `pardos-network` (bridge) - ComunicaciÃ³n interna entre servicios
- **VolÃºmenes:**
  - `ollama_data` - Modelos y configuraciÃ³n de Ollama
  - `portainer_data` - ConfiguraciÃ³n de Portainer

---

### ğŸ“¦ Pasos para desplegar

1ï¸âƒ£ **SubÃ­ el proyecto a tu instancia EC2**
```
scp -i tu-llave.pem IA-pardo-updated-complete.zip ec2-user@<EC2_PUBLIC_IP>:~/
```

2ï¸âƒ£ **Conectate a la instancia**
```
ssh -i tu-llave.pem ec2-user@<EC2_PUBLIC_IP>
```

3ï¸âƒ£ **InstalÃ¡ Docker y Docker Compose (si no lo hiciste aÃºn)**
```
sudo dnf install -y docker
sudo systemctl start docker
sudo systemctl enable docker
sudo usermod -aG docker ec2-user
exit
ssh -i tu-llave.pem ec2-user@<EC2_PUBLIC_IP>

sudo curl -SL https://github.com/docker/compose/releases/download/v2.27.1/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
docker-compose version
```

4ï¸âƒ£ **DescomprimÃ­ el proyecto**
```
unzip IA-pardo-updated-complete.zip -d IA-pardo
cd IA-pardo
```

5ï¸âƒ£ **(Opcional) QuitÃ¡ el warning del compose**
EditÃ¡ `docker-compose.yml` y eliminÃ¡ la lÃ­nea:
```
version: '3.8'
```

6ï¸âƒ£ **Build de las imÃ¡genes**
```
docker-compose build
```

7ï¸âƒ£ **LevantÃ¡ todos los servicios**
```
docker-compose up -d
```

---

### ğŸ” CÃ³mo monitorear el estado de los contenedores

âœ… Ver los contenedores corriendo:
```
docker-compose ps
```

âœ… Monitorear logs en tiempo real:
```
docker-compose logs -f
```
PresionÃ¡ `Ctrl + C` para salir del seguimiento.

âœ… Ver todos los contenedores (incluyendo parados):
```
docker ps -a
```

âœ… Si querÃ©s inspeccionar uno especÃ­fico:
```
docker logs <nombre_contenedor>
```
Por ejemplo:
```
docker logs pardos-backend
```

âœ… Si necesitÃ¡s ver el uso de recursos (CPU, memoria):
```
docker stats
```

---

### ğŸŒ **Accesos finales**

- **Frontend presentaciÃ³n:**
  ```
  http://<EC2_PUBLIC_IP>
  ```

- **Chat con MatÃ­as Pardo:**
  ```
  http://<EC2_PUBLIC_IP>/chat/index.html
  ```

- **InterCode (Generador de CÃ³digo Java):**
  ```
  http://<EC2_PUBLIC_IP>/code/index.html
  ```

- **Portainer (AdministraciÃ³n Docker):**
  ```
  http://<EC2_PUBLIC_IP>:9000
  ```

### ğŸ”Œ **API Endpoints del Backend**

| Endpoint | MÃ©todo | DescripciÃ³n | Puerto |
|----------|--------|-------------|--------|
| `/api/chat` | POST | Chat con modelos de IA | 3000 |
| `/api/models` | GET | Listar modelos disponibles | 3000 |

#### **1. Chat con IA - `/api/chat`**
**DescripciÃ³n:** EnvÃ­a mensajes a los modelos de IA y recibe respuestas.

**Body (JSON):**
```json
{
  "prompt": "Tu mensaje aquÃ­",
  "model": "nombre-del-modelo" // Opcional, default: pardos-assistant:latest
}
```

**Ejemplos:**
```bash
# Modelo personalizado (default)
curl -X POST http://<EC2_PUBLIC_IP>:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Hola MatÃ­as, contame sobre tu experiencia"}'

# Modelo de cÃ³digo Java
curl -X POST http://<EC2_PUBLIC_IP>:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Crea una clase Usuario con patrÃ³n Builder", "model": "pardos-code:latest"}'

# Modelo base especÃ­fico
curl -X POST http://<EC2_PUBLIC_IP>:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Hello, how are you?", "model": "llama3:8b"}'
```

**Respuesta:**
```json
{
  "reply": "Respuesta del modelo de IA..."
}
```

#### **2. Listar Modelos - `/api/models`**
**DescripciÃ³n:** Obtiene todos los modelos instalados en Ollama.

**Ejemplo:**
```bash
curl http://<EC2_PUBLIC_IP>:3000/api/models
```

**Respuesta:**
```json
{
  "models": [
    {
      "name": "pardos-assistant:latest",
      "size": 4661224676,
      "digest": "sha256:..."
    },
    {
      "name": "llama3:8b",
      "size": 4661224676,
      "digest": "sha256:..."
    },
    {
      "name": "llama3-base",
      "size": 4661224676,
      "digest": "sha256:..."
    }
  ]
}
```

### ğŸ§ª **Testing con Postman**

**URL Base:** `http://<EC2_PUBLIC_IP>:3000`

**Headers necesarios:**
- `Content-Type: application/json`

**Timeout configurado:** 10 minutos (para respuestas largas de IA)

### ğŸ¤– **Modelos de IA disponibles**

El sistema incluye **3 modelos de Ollama:**

1. **`llama3:8b`** - Modelo base de Meta
2. **`pardos-assistant:latest`** - Modelo personalizado con datos de MatÃ­as Pardo
   - Entrenado con informaciÃ³n personal y profesional
   - Responde como MatÃ­as en primera persona
   - Incluye experiencia laboral, proyectos y estudios
3. **`pardos-code:latest`** - Modelo especializado en cÃ³digo Java
   - Optimizado para generar cÃ³digo con buenas prÃ¡cticas
   - Sigue principios SOLID y patrones de diseÃ±o
   - Respuestas directas sin explicaciones adicionales

### âš™ï¸ **ParÃ¡metros de configuraciÃ³n de modelos**

Cada modelo usa parÃ¡metros especÃ­ficos en sus archivos `diag` para optimizar su comportamiento:

#### **PARAMETER temperature**
- **Rango:** 0.0 - 2.0
- **FunciÃ³n:** Controla la creatividad/aleatoriedad de las respuestas
- **Valores:**
  - `0.1` (pardos-code) - Respuestas muy precisas y determinÃ­sticas
  - `0.7` (llama3-base) - Balance entre creatividad y precisiÃ³n
  - `1.0` (pardos-assistant) - Respuestas mÃ¡s creativas y naturales

#### **PARAMETER top_p**
- **Rango:** 0.0 - 1.0
- **FunciÃ³n:** Controla la diversidad de palabras consideradas
- **Valor:** `0.9` - Considera el 90% de las opciones mÃ¡s probables

#### **PARAMETER num_ctx**
- **FunciÃ³n:** Define el tamaÃ±o del contexto (memoria)
- **Valor:** `4096` tokens - Permite conversaciones largas

#### **PARAMETER stop**
- **FunciÃ³n:** Tokens que indican fin de respuesta
- **Valores:** `<|start_header_id|>`, `<|end_header_id|>`, `<|eot_id|>`

#### **TEMPLATE**
- **FunciÃ³n:** Define el formato de conversaciÃ³n
- **Estructura:** Sistema â†’ Usuario â†’ Asistente
- **Tokens especiales:** Marcan inicio/fin de cada rol

**Ver modelos instalados:**
```bash
# Desde lÃ­nea de comandos
docker exec -it pardos-ollama ollama list

# Desde API del backend
curl http://<EC2_PUBLIC_IP>:3000/api/models
```

---

### âš™ Comandos Ãºtiles

âœ… Apagar todos los servicios:
```
docker-compose down
```

âœ… Forzar rebuild y reinicio:
```
docker-compose build --no-cache
docker-compose up -d --force-recreate
```

âœ… Actualizar imÃ¡genes desde Docker Hub (si usÃ¡s imÃ¡genes remotas):
```
docker-compose pull
docker-compose up -d --force-recreate
```

---

âš  **NOTAS IMPORTANTES:**
- **Backend expuesto en puerto 3000** para acceso directo con Postman/curl
- **Ollama interno** - Solo el backend puede comunicarse con Ã©l
- **Sistema sin SSL** - Funciona completamente con HTTP
- **Timeout de 10 minutos** - Configurado en backend y frontend
- **3 modelos disponibles** - Personalizado, base y optimizado
- **Portainer integrado** - AdministraciÃ³n web en puerto 9000
